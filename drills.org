#+STARTUP: latexpreview
* Math / Stats
** Basic Rules of Probability
*** Drills
**** Additivity                                                    :drill:
$P(A \vee B) = \ ?$
***** Answer
$P(A \vee B) = P(A) + P(B) - P(A \wedge B)$
**** Conditional Probability                                       :drill:
$P(A|B) = \ ?$

Do not answer with Bayes' rule. The answer should contain $P(A \wedge B)$.
***** Answer
$P(A|B) = \frac{P(A \wedge B)}{P(B)}$
**** Multiplication                                                :drill:
$P(A \wedge B) = \ ?$
***** Answer
$P(A \wedge B) = P(A|B)P(B)$
**** Total Probability                                             :drill:
How is $P(A)$ related to $B$ ?
***** Answer
$P(A) = P(A|B)P(B) + P(A| \neg B)P( \neg B)$
**** Bayes' Rule                                                   :drill:
What is Bayes' rule?
***** Answer
$P(A|B) = \frac{ P(B|A)P(A) }{ \sum_{i} P(B|A_i)P(A_i) } = \frac{ P(B|A)P(A) }{ P(B) }$
**** Standard Deviation of Population                              :drill:
What is the standard deviation for a population?
***** Answer
$\sqrt{\sum_{i} [(X_i - X_A) ^ 2] / n}$ where $X_A$ is the average for the population.
**** Standard Deviation Given P and N                              :drill:
What is the standard deviation if given $p$ and $n$ ?
***** Answer
$\sigma = \sqrt{(1-p)pn}$
**** Worst Case Confidence Interval                                :drill:
What's a good rule of thumb for the worst case confidence interval if given $p$ and $n$?
***** Answer
Use $\sigma = \sqrt{(1-p)pn}$ where $p = 0.5$, because when $p = 0.5$, $\sigma$ is maximized for any given $n$.
**** Three Sigma Rule                                              :drill:
What is the "three sigma rule"? (Hint: It's related to standard deviations.)
***** Answer
"68% - 95% - 99.7%"

These are the percentages of values that lie within 1, 2, and 3 standard deviations of a mean.
** Greek Alphabet
*** Drills
**** gamma                                                         :drill:
What is this Greek letter? $\gamma$
***** Answer
Lowercase gamma
**** Gamma                                                         :drill:
What is this Greek letter? $\Gamma$
***** Answer
Uppercase gamma
**** delta                                                         :drill:
What is this Greek letter? $\delta$
***** Answer
Lowercase delta
**** Delta                                                         :drill:
What is this Greek letter? $\Delta$
***** Answer
Uppercase delta
**** epsilon                                                       :drill:
What is this Greek letter? $\epsilon$
***** Answer
Lowercase epsilon
**** theta                                                         :drill:
What is this Greek letter? $\theta$
***** Answer
Lowercase theta
**** Theta                                                         :drill:
What is this Greek letter? $\Theta$
***** Answer
Uppercase theta
**** lambda                                                        :drill:
What is this Greek letter? $\lambda$
***** Answer
Lowercase lambda
**** Lambda                                                        :drill:
What is this Greek letter? $\Lambda$
***** Answer
Uppercase lambda
**** mu                                                            :drill:
What is this Greek letter? $\mu$
***** Answer
Lowercase mu
**** pi                                                            :drill:
What is this Greek letter? $\pi$
***** Answer
Lowercase pi
**** Pi                                                            :drill:
What is this Greek letter? $\Pi$
***** Answer
Uppercase pi
**** rho                                                           :drill:
What is this Greek letter? $\rho$
***** Answer
Lowercase rho
**** sigma                                                         :drill:
What is this Greek letter? $\sigma$
***** Answer
Lowercase sigma
**** Sigma                                                         :drill:
What is this Greek letter? $\Sigma$
***** Answer
Uppercase sigma
**** phi                                                           :drill:
What is this Greek letter? $\phi$
***** Answer
Lowercase phi
**** Phi                                                           :drill:
What is this Greek letter? $\Phi$
***** Answer
Uppercase phi
**** psi                                                           :drill:
What is this Greek letter? $\psi$
***** Answer
Lowercase psi
**** Psi                                                           :drill:
What is this Greek letter? $\Psi$
***** Answer
Uppercase psi
**** omega                                                         :drill:
What is this Greek letter? $\omega$
***** Answer
Lowercase omega
**** Omega                                                         :drill:
What is this Greek letter? $\Omega$
***** Answer
Uppercase omega
** Bayesian Analysis
*** Drills
**** Normal Distribution                                           :drill:
What is the normal distribution formula?
***** Answer
$p(x) = \frac{1}{\sigma \sqrt{2 \pi}} e^{(-\frac{1}{2}[\frac{x-\mu}{\sigma}]^2)$

Where $\mu$ is the mean (average), and $\sigma$ is the standard deviation.
**** Variance                                                      :drill:
What is variance? How does it relate to the standard deviation?
***** Answer
$variance = \sigma^2 = \frac{\sum_i{(X_i - \mu)^2}}{N}$

$standard\ deviation = \sqrt{variance}$

In other words, variance is the average squared difference (or "mean squared error"). The standard deviation is the square root of the variance.
**** Deriving Bayes' Rule                                          :drill:
Derive Bayes' rule from $p(a|b) = \frac{p(b,a)}{p(b)}$
***** Answer
Multiply both sides by $p(b)$: $p(a|b) = \frac{p(b,a)}{p(b)} \implies p(b,a) = p(a|b)p(b)$

"and" is commutative: $p(a,b) = p(b,a)$

Substitute the long form of $p(a,b)$ and $p(b,a)$: $p(b|a)p(a) = p(a|b)p(b)$

Divide both sides by $p(b)$: $\frac{p(b|a)p(a)}{p(b)} = p(a|b)$

That is Bayes' rule. Remember that $p(b) = \sum_{a_i} p(b|a_i)p(a_i)$
**** Parts of Bayes' Rule                                          :drill:
What are the four parts of Bayes' rule?
***** Answer
$p(a|b) = \frac{p(b|a)p(a)}{p(b)}$

$p(a|b)$ is the "posterior".

$p(b|a)$ is the "likelihood".

$p(a)$ is the "prior".

$p(b)$ is the "evidence".
**** Beta Distribution                                             :drill:
What is the Beta distribution?
***** Answer
$beta(x|a,b) = \frac{x^{(a-1)}(1-x)^{(b-1)}}{\int_0^1 x^{(a-1)}(1-x)^{(b-1)}\ dx}$

The denominator is a "normalizing constant" which causes the probability function to sum to 1.

Some guidelines for choosing a and b:

$mean = \mu = a/(a+b)$

$mode = \omega = (a-1)/(a+b-2)$

$concentration = k = a + b$

Concentration is the number of data points needed to equally balance the prior.
**** Metropolis Algorithm                                          :drill:
What is the Metropolis algorithm?
***** Answer
It is a "random walk", or Monte Carlo Markov Chain (MCMC) algorithm, for sampling a distribution.

The algorithm is:

1) Keep track of the "current position" in the distribution and all previously visited positions.

2) Generate a proposed move to another position. There are various ways to do this, some are more effective than others.

3) Move from the current position to the proposed position with probability:

$p(move) = min(1, \frac{d(proposed)}{d(current)})$

Where $d$ is the distribution we are sampling.

4) In an infinitely long run, the history of visited positions will be a perfect sample from the distribution.

With the right parameters, a finitely long run will be a good sample from the distribution.
** Linear Algebra
*** Drills
**** Row / Column Notation                                         :drill:
If I have a 2 x 3 matrix, how many rows and columns does it have?
***** Answer
2 rows
3 columns
**** What Size?                                                    :drill:
What size is this matrix?

\begin{bmatrix}
a & b \\
c & d \\
e & f
\end{bmatrix}
***** Answer
3 x 2

3 rows
2 columns
**** Matrix Multiplication                                         :drill:
Perform this matrix multiplication:

\begin{equation*}
\begin{bmatrix}
a & b \\
c & d
\end{bmatrix}
\begin{bmatrix}
e & f \\
g & h
\end{bmatrix}
\end{equation*}
***** Answer
\begin{equation*}
\begin{matrix}
\begin{bmatrix} a & b \end{bmatrix} \begin{bmatrix} e \\ g \end{bmatrix}
&
\begin{bmatrix} a & b \end{bmatrix} \begin{bmatrix} f \\ h \end{bmatrix}
\\[1em]
\begin{bmatrix} c & d \end{bmatrix} \begin{bmatrix} e \\ g \end{bmatrix}
&
\begin{bmatrix} c & d \end{bmatrix} \begin{bmatrix} f \\ h \end{bmatrix}
\end{matrix}
=
\begin{bmatrix}
ae + bg & af + bh \\
ce + dg & cf + dh
\end{bmatrix}
\end{equation*}

Notice that *rows* from the first matrix tend to stay together, and *columns* from the second matrix tend to stay together.
**** Matrix Multiplication Meaning                                 :drill:
What is the meaning of the following matrix multiplication with regards to basis vectors?

\begin{equation*}
\begin{bmatrix}
a & b \\ c & d
\end{bmatrix}
\begin{bmatrix}
e \\ f
\end{bmatrix}
\end{equation*}
***** Answer
\begin{equation*}
e
\begin{bmatrix}
a \\ c
\end{bmatrix}
+
f
\begin{bmatrix}
b \\ d
\end{bmatrix}
=
\begin{bmatrix}
ea + fb \\ ec + fd
\end{bmatrix}
\end{equation*}

$\begin{bmatrix} a \\ c \end{bmatrix}$ and $\begin{bmatrix} b \\ d \end{bmatrix}$ are the basis vectors that are scaled by $\begin{bmatrix} e \\ f \end{bmatrix}$.

Remember all vectors are defined in terms of their basis vectors.
**** "Eigen"                                                       :drill:
What does the word "eigen" (as in "eigenvector") mean in German?
***** Answer
"own"

It helps to think of "eigenvectors" as "owned vectors".
**** Eigen Equation                                                :drill:
What is the eigenvector / eigenvalue equation?
***** Answer
$Ax = \lambda x$

Where $A$ is a linear transformation (a matrix),
$x$ is a vector,
and $\lambda$ is a scalar.

For any solution to this equation, $x$ is a /eigenvector/ of $A$, and $\lambda$ is a /eigenvalue/ of $A$.

They are "right" eigenvectors and eigenvalues, because the $x$ is on the right in "$Ax$". There are also "left" eigenvectors and eigenvalues.
**** Vector Space                                                  :drill:
Roughly speaking, what are the requirements for a vector space?
***** Answer
Must be closed under addition and scaling (scalar multiplication), and these operations must "behave normally". Any "vector" that meets these criteria forms a vector space.
**** Norm Function                                                 :drill:
What is the "norm" function?
***** Answer
It is a generalization of the Pythagorean formula to many variables:

$norm(x) = \sqrt{x_1^2 + ... + x_n^2}$
** Algebra
*** Drills
**** Quadratic Formula                                             :drill:
What is the quadratic formula?
***** Answer
The two solutions to $ax^2 + bx + c = 0$ are given by the quadratic formula:

$x = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}$
**** Logarithm                                                     :drill:
Rearrange the variables $a$, $b$, and $c$, in the following so that it becomes true:

$log_{a}(b) = c \quad if \quad a^{b} = c$
***** Answer
$log_{b}(a) = c \quad if \quad b^{c} = a$
** Calculus
*** Drills
**** General Formula for the Derivative                            :drill:
What is the general formula for the derivative?
***** Answer
$y' = \frac{f(x+h) - f(x)}{h}$
* Programming
** Haskell
*** Drills
**** Functor                                                       :drill:
What is the minimal class definition of ~Functor~?
***** Answer
#+begin_src haskell
  class Functor f where
    fmap :: (a -> b) -> f a -> f b
#+end_src
**** Applicative                                                   :drill:
What is the minimal class definition of ~Applicative~?

Hint: there are 3 methods, but only 2 must be implemented.
***** Answer
#+begin_src haskell
  class Functor f => Applicative f where
    pure :: a -> f a
    (<*>) :: f (a -> b) -> f a -> f b
    liftA2 :: (a -> b -> c) -> f a -> f b -> f c
#+end_src
**** Monad                                                         :drill:
What is the minimal class definition of ~Monad~?
***** Answer
#+begin_src haskell
  class Applicative m => Monad m where
    (>>=) :: m a -> (a -> m b) -> m b
#+end_src
**** Monad Transformers                                            :drill:
What is the data definition of ~MaybeT~ and ~EitherT~?
***** Answer
#+begin_src haskell
  newtype MaybeT m a = MaybeT { runMaybeT :: m (Maybe a) }
  newtype EitherT e m a = EitherT { runEitherT :: m (Either e a) }
#+end_src
**** MaybeT Monad Instance                                         :drill:
Complete the following definitions:

(Copy / paste the code into a Haskell buffer to complete.)

#+begin_src haskell
  newtype MaybeT m a = MaybeT { runMaybeT :: m (Maybe a) }

  instance (Functor m) => Functor (MaybeT m) where
    fmap :: (a -> b) -> MaybeT m a -> MaybeT m b
    fmap = _TODO

  instance (Applicative m) => Applicative (MaybeT m) where
    pure :: a -> MaybeT m a
    pure = _TODO
    (<*>) :: MaybeT m (a -> b) -> MaybeT m a -> MaybeT m b
    (<*>) = _TODO

  instance (Monad m) => Monad (MaybeT m) where
    (>>=) :: MaybeT m a -> (a -> MaybeT m b) -> MaybeT m b
    (>>=) = _TODO
#+end_src
**** sequence                                                      :drill:
Finish this definition:

(Note: There are extra parenthesis in the definition to prevent org-drill's "cloze" behavior.)

#+begin_src haskell
  sequence :: Applicative f => [(f a)] -> f [(a)]
  sequence = _TODO
#+end_src
***** Answer
#+begin_src haskell
  sequence :: Applicative f => [f a] -> f [a]
  sequence = foldr (liftA2 (:)) (pure [])
#+end_src
**** Fold Types                                                    :drill:
What are the types of ~foldr~ and ~foldl~?
***** Answer
#+begin_src haskell
  foldr :: (a -> b -> b) -> b -> [a] -> b
  foldl :: (b -> a -> b) -> b -> [a] -> b
#+end_src
** JavaScript
*** Drills
**** Comparison Conversions                                        :drill:
In JavaScript, when comparing ~x == y~ what type conversions might take place, and in what order?
***** Answer
The conversion rules in order of priority are roughly:
    1. Boolean -> Number
    2. any -> Number
    3. any -> String
**** Falsy Values                                                  :drill:
In Javascript, what are the 6 falsy values?
***** Answer
1. ~false~ of type ~Boolean~
2. ~0~ of type ~Number~
3. ~NaN~ of type ~Number~
4. ~""~ , the empty ~String~
5. ~null~ of type ~null~
6. ~undefined~ of type ~undefined~
** Machine Learning
*** Drills
**** Softmax Function                                              :drill:
What is the softmax function?
***** Answer
It is a function which creates a probability distribution from weights:

$\sigma(z)_i = \frac{e^{z_i}}{\Sigma_j e^{z_j}}$
**** L1 and L2 Regularization                                      :drill:
What is L1 and L2 regularization? What are they also known as?
***** Answer
L1 regularization is also known as "Lasso regression".

L2 regularization is also known as "Ridge regression".

L1 regularization penalizes the /sum/ of the parameters. This encourages only the most important parameters to become large, while most parameters remain zero.

L2 regularization penalizes the /norm/ of the parameters. This encourages all parameters to be used and increasingly penalizes any parameters that become large.
**** Entropy                                                       :drill:
What is the entropy function?
***** Answer
$entropy(X) = -\Sigma_i P(X_i) log_b(P(X_i))$ where $P(X_i)$ is a probability, and $X$ forms a discrete probability distribution.

It is a function which is maximized when the probabilities are evenly distributed.
